// Each #kernel tells which function to compile; you can have many kernels
//#pragma kernel FragmentBufferBuild
#pragma kernel TileBufferBuild
#pragma kernel TileBufferSplat
#pragma kernel SortFragments
#pragma kernel Convolve
#pragma kernel BlurTest
#pragma kernel InterpolatePSFTexture
#pragma kernel InterpolatePSFTextureRight

#pragma kernel TileBufferBuildEditor
#pragma kernel ConvolveEditor

//#pragma enable_cbuffer

#define FLT_MAX 3.402823466e+38F

/* These must be synced with constants in the render pass */
#define TILE_SIZE 16
#define SHARED_ARRAY_SIZE 256 // TILE_SIZE * TILE_SIZE

#define TILE_MAX_FRAGMENTS 4096
#define SORT_GROUP_SIZE 1024

#define SORT_ELEMENTS_PER_THREAD 2 // TILE_MAX_FRAGMENTS / SORTGROUP_SIZE / 2

#define BOX_BLUR_RADIUS 8
#define BOX_BLUR_WEIGHT (1.0f / 289.0f) // 1 / (2 * BOX_BLUR_RADIUS + 1)^2

#define CEIL_DIV(x, y) ((x - 1) / y + 1)

#define RIGHT_EYE (eyeIndex == 1 && separateAberrations)

//CBUFFER_START(TileSplatParams)
cbuffer TileSplatParams
{
    bool separateAberrations;

    uint2 numTiles;
    uint2 resolution;

    uint minBlurRadiusCurrent;
    uint maxBlurRadiusCurrent;

    uint rightMinBlurRadiusCurrent;
    uint rightMaxBlurRadiusCurrent;
    
    // assumed that sampling parameters are always same, which is probably reasonable
    uint numObjectDioptres;
    float objectDioptresMin;
    float objectDioptresMax;
    float objectDioptresStep;
    uint numApertures;
    float aperturesMin;
    float aperturesMax;
    float aperturesStep;
    uint numFocusDioptres;
    float focusDioptresMin;
    float focusDioptresMax;
    float focusDioptresStep;
};
//CBUFFER_END

cbuffer CameraData
{
    float aperture;
    float focusDistance;
    
    // pinhole camera parameters (clipping planes + frustum extents; near is not necessarily needed at the moment)
    float nearClip;
    float farClip;
    
    float3 cameraPosition; // world-space
    float3 rightCameraPosition;

    float3 farLowerLeft; // view-space
    float3 farUpperLeft;
    float3 farUpperRight;
    float3 farLowerRight;

    float3 rightFarLowerLeft; // view-space
    float3 rightFarUpperLeft;
    float3 rightFarUpperRight;
    float3 rightFarLowerRight;
};

struct FragmentData
{
    float3 color;
    float2 screenPosition;
    float psfIndex; // depth of some kind
    float blurRadius;
};

RWStructuredBuffer<FragmentData> fragmentBuffer;

RWStructuredBuffer<uint> tileFragmentCountBuffer; // num of fragments in each tile

struct SortIndex
{
    uint fragmentIndex;
    float depth; // uses "sort" depth which adds a term based on index to avoid Z-fighting
};

RWStructuredBuffer<SortIndex> tileSortBuffer;

Texture2D<float4> iColor;
RWTexture2D<float4> oColor;
Texture2D<float2> iDepth;

// Used for XR single pass instanced
Texture2DArray<float4> iColorArray;
RWTexture2DArray<float4> oColorArray;

// depth is stored in .x
Texture2DArray<float2> iDepthArray;

struct PsfParam {
    uint minBlurRadius; // px
    uint maxBlurRadius; // px
    uint weightStartIndex;
    float blurRadiusDeg;
};

StructuredBuffer<float> psfWeights;
StructuredBuffer<PsfParam> psfParams;

// Interpolate PsfParam to squeeze away the aperture diameter and focus distance dimensions (these are fixed in a given frame)
// Unlike Csoba, we perform the calculation of 3D texture on CPU instead
struct InterpolatedPsfParam
{
    uint startLayer;
    uint numLayers;
    float blurRadius;
};

StructuredBuffer<InterpolatedPsfParam> interpolatedPsfParams;
StructuredBuffer<uint> psfInterpolationBuffer; // note: 1-indexed, 0th entry contains total count

// 2 "views" into the same underlying texture - must use psfImage to write, then psfTexture to read
// HLSL runtime enforces that the same underlying texture resource cannot be used both in read and write mode
// Need the "read" view even though RWTexture would suggest it is also readable, because RWTexture3D doesn't support
// texture sampling, which we need

// also Csoba's code uses r11_g11_b10 (11 bits for R, G and 10 bits for B) to compress the texture memory used by default
// float4 is probably simpler? we could also consider this optimization in the future.
RWTexture3D<float4> psfImage;
Texture3D<float4> psfTexture;

// a small optimization to reduce # of texture fetches; cull away fetches to parts of PSF texture we know must be black
StructuredBuffer<uint> psfTextureLayerExtents;

// support for stereo
StructuredBuffer<InterpolatedPsfParam> rightInterpolatedPsfParams;
// HLSL doesn't support Texture3DArray natively, so have to bind two textures
Texture3D<float4> rightPsfTexture;
StructuredBuffer<uint> rightPsfTextureLayerExtents;


float3 ApertureIndices(float aperture)
{
    float frac = (aperture - aperturesMin) / aperturesStep;
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 low = int2(0, 0);
    int2 high = int2(numApertures - 1, numApertures - 1);
    int2 clampedIndices = clamp(unclampedIndices, low, high);
    return float3(clampedIndices.x, clampedIndices.y, clamp(frac, 0, numApertures - 1));
}

float3 FocusIndices(float focusDistance)
{
    float focusDioptres = 1.0f / focusDistance;
    float frac = (focusDioptres - focusDioptresMin) / focusDioptresStep;
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 low = int2(0, 0);
    int2 high = int2(numFocusDioptres - 1, numFocusDioptres - 1);
    int2 clampedIndices = clamp(unclampedIndices, low, high);
    return float3(clampedIndices.x, clampedIndices.y, clamp(frac, 0, numFocusDioptres - 1));
}

float3 ObjectIndices(float objectDistance)
{
    float objectDioptres = 1.0f / objectDistance;
    float frac = (objectDioptres - objectDioptresMin) / objectDioptresStep;
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 low = int2(0, 0);
    int2 high = int2(numObjectDioptres - 1, numObjectDioptres - 1);
    int2 clampedIndices = clamp(unclampedIndices, low, high);
    return float3(clampedIndices.x, clampedIndices.y, clamp(frac, 0, numObjectDioptres - 1));
}

// d = object distance index, c = channel index. We assume rank of channel dimension is always 3 (RGB)
uint PsfParamArrayIndex(uint d, uint c)
{
    return d * 3 + c;
}

// l = layer ID, d = "base" PSF that l is associated with
float LayerIdToPsfIndex(uint d, uint l)
{
    uint idx = PsfParamArrayIndex(d, 0); // start layer + num layers is only stored in R entry
    uint s = interpolatedPsfParams[idx].startLayer;
    uint n = interpolatedPsfParams[idx].numLayers;
    return d + float(l - s) / float(n);
}

float3 LayerIdToPsfIndices(uint d, uint l)
{
    float frac = LayerIdToPsfIndex(d, l);
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 clampedIndices = clamp(unclampedIndices, 0, numObjectDioptres - 1);
    return float3(clampedIndices.x, clampedIndices.y, frac);
}

float LerpPsfRadius(float3 d, uint c)
{
    float psfRadius0 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[0], c)].blurRadius;
    float psfRadius1 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[1], c)].blurRadius;
    return lerp(psfRadius0, psfRadius1, frac(d[2]));
}

float LerpPsfRadiusStereo(float3 d, uint c, uint eyeIndex) 
{
    if (RIGHT_EYE)
    {
        float psfRadius0 = rightInterpolatedPsfParams[PsfParamArrayIndex((uint) d[0], c)].blurRadius;
        float psfRadius1 = rightInterpolatedPsfParams[PsfParamArrayIndex((uint) d[1], c)].blurRadius;
        return lerp(psfRadius0, psfRadius1, frac(d[2]));
    }
    else
    {
        float psfRadius0 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[0], c)].blurRadius;
        float psfRadius1 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[1], c)].blurRadius;
        return lerp(psfRadius0, psfRadius1, frac(d[2]));
    }
}

bool IsSamplePadding(int2 sampleCoords, float3 psfIds, uint stereoMaxBlurRadiusCurrent)
{
    // calculate largest blur radius across all channels
    float maxBlurRadius = 0.0f;
    for (int i = 0; i < 3; i += 1)
    {
        float blurRadius = LerpPsfRadius(psfIds, i);
        maxBlurRadius = max(maxBlurRadius, blurRadius);
    }

    int lowerLeftXY = int(stereoMaxBlurRadiusCurrent) - maxBlurRadius;
    int upperRightXY = int(stereoMaxBlurRadiusCurrent) + maxBlurRadius;
    int2 lowerLeft = int2(lowerLeftXY, lowerLeftXY);
    int2 upperRight = int2(upperRightXY, upperRightXY);
    bool isPadding = any(sampleCoords < lowerLeft) || any(sampleCoords > upperRight);
    return isPadding;
}

// bilinear interpolation
float lerp2(
    float f00,
    float f01,
    float f10,
    float f11,
    float x01,
    float x10
)
{
    float a = lerp(f00, f01, x01);
    float b = lerp(f10, f11, x01);
    return lerp(a, b, x10);
}

// trilinear interpolation
float lerp3(
    float f000,
    float f001,
    float f010,
    float f011,
    float f100,
    float f101,
    float f110,
    float f111,
    float x001,
    float x010,
    float x100
)
{
    float a = lerp2(f000, f001, f010, f011, x001, x010);
    float b = lerp2(f100, f101, f110, f111, x001, x010);
    return lerp(a, b, x100);
}

uint PsfParamBufferIndex(uint d, uint a, uint f, uint c)
{
    return d * (3 * numApertures * numFocusDioptres)
        + c * (numApertures * numFocusDioptres)
        + a * (numFocusDioptres)
        + f;
}

// closed form sum of (2r+1)^2 for r from a to b (inclusive) 
// apparently calculated using Mathematica
uint WeightOffset(int a, int b)
{
    return uint(a - 4 * a * a * a + (1 + b) * (1 + 2 * b) * (3 + 2 * b)) / 3;
}

uint PsfWeightBufferIndex(uint psfParamIdx, uint r, uint minR, uint2 sc)
{
    uint base = psfParams[psfParamIdx].weightStartIndex;
    uint sampleOffset = sc.y * (2 * r + 1) + sc.x;
    if (r == minR)
    {
        return base + sampleOffset;
    }
    else
    {
        return base + WeightOffset(minR, r - 1) + sampleOffset;
    }

}

float PsfWeight(uint psfParamIdx, uint r, uint2 sc)
{
    uint minR = psfParams[psfParamIdx].minBlurRadius;
    uint maxR = psfParams[psfParamIdx].maxBlurRadius;
    return (r >= minR && r <= maxR) ? psfWeights[PsfWeightBufferIndex(psfParamIdx, r, minR, sc)] : 0.0f;
}

float SamplePsfWeightBufferPadded(float3 d, float3 a, float3 f, uint c, uint r, uint2 scp, uint stereoMaxBlurRadiusCurrent)
{
    // remove padding from sample coordinates
    int2 sc = int2(scp) - stereoMaxBlurRadiusCurrent + r;
    
    // determine if we are outside the spatial extent of the PSF entry we are sampling
    int2 lowerLeft = int2(0, 0);
    int2 upperRight = int2(2 * r + 1, 2 * r + 1);
    if (any(sc < lowerLeft) || any(sc >= upperRight))
    {
        return 0.0f;
    }
    
    // trilinearly interpolate over object distance, aperture diameter, focus distance
    return lerp3(
        PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[0], (uint) f[0], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[0], (uint) f[1], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[1], (uint) f[0], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[1], (uint) f[1], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[0], (uint) f[0], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[0], (uint) f[1], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[1], (uint) f[0], c), r, sc),
        PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[1], (uint) f[1], c), r, sc),
        frac(f[2]),
        frac(a[2]),
        frac(d[2])
    );
}

float SamplePsfWeightBufferPadded(float3 d, float3 a, float3 f, uint c, float3 r, uint2 scp, uint stereoMaxBlurRadiusCurrent)
{
    return lerp(
        SamplePsfWeightBufferPadded(d, a, f, c, (uint) r[0], scp, stereoMaxBlurRadiusCurrent),
        SamplePsfWeightBufferPadded(d, a, f, c, (uint) r[1], scp, stereoMaxBlurRadiusCurrent),
        frac(r[2])
    );
}


// default from Csoba's code
#define INTERPOLATION_GROUP_SIZE 8

// Interpolate PSFs to squeeze away the aperture diameter / focus distance dimensions, and also rearrange data into a 3D texture so that
// we can utilize hardware texture samplers to get good performance

void InterpolatePSFTextureHelper(uint3 id_in_tile, uint eyeIndex)
{
    // psfImage[id_in_tile] = float4(1.0f, 0.0f, 0.0f, 1.0f);
    // return; 

    uint2 sampleCoords = id_in_tile.xy;
    uint layerId = id_in_tile.z;

    float3 apertureIds = ApertureIndices(aperture);
    float3 focusIds = FocusIndices(focusDistance);
    uint psfId = psfInterpolationBuffer[layerId + 1];
    float3 psfIds = LayerIdToPsfIndices(psfId, layerId);
    
    uint numTextureLayers = psfInterpolationBuffer[0];
    if (layerId >= numTextureLayers)
    {
        // psfImage[id_in_tile] = float4(1.0f, 0.0f, 0.0f, 1.0f);
        return;
    }
    
    uint stereoMaxBlurRadiusCurrent = RIGHT_EYE ? rightMaxBlurRadiusCurrent : maxBlurRadiusCurrent;
    if (IsSamplePadding(sampleCoords, psfIds, stereoMaxBlurRadiusCurrent))
    {
        // psfImage[id_in_tile] = float4(0.0f, 1.0f, 0.0f, 1.0f);
        return;
    }
    
    // psfImage[id_in_tile] = float4(focusIds[0], focusIds[1], focusIds[2], 1.0f);
    // return;
    
    float4 textureValue = float4(0.0f, 0.0f, 0.0f, 1.0f);
    for (uint c = 0; c < 3; c += 1)
    {
        float rFrac = LerpPsfRadius(psfIds, c);
        // textureValue[c] = rFrac;
        float3 r = float3(floor(rFrac), ceil(rFrac), rFrac);
        textureValue[c] = SamplePsfWeightBufferPadded(psfIds, apertureIds, focusIds, c, r, sampleCoords, stereoMaxBlurRadiusCurrent);
    }
    
    psfImage[id_in_tile] = textureValue;
    
}

[numthreads(INTERPOLATION_GROUP_SIZE, INTERPOLATION_GROUP_SIZE, 1)]
void InterpolatePSFTexture(uint3 id_in_tile : SV_DispatchThreadID)
{
    InterpolatePSFTextureHelper(id_in_tile, 0);
}

[numthreads(INTERPOLATION_GROUP_SIZE, INTERPOLATION_GROUP_SIZE, 1)]
void InterpolatePSFTextureRight(uint3 id_in_tile : SV_DispatchThreadID)
{
    InterpolatePSFTextureHelper(id_in_tile, 1);
}




// Index for fragmentBuffer
uint FragmentArrayIndex(const uint2 fragmentCoord, const uint eyeIndex)
{
    return fragmentCoord.y * resolution.x + fragmentCoord.x + eyeIndex * resolution.x * resolution.y;
}

// Index for tileSortBuffer, first index of fragment in that tile
uint TileArrayIndex(const uint2 tileCoord, const uint eyeIndex)
{
    return (tileCoord.y * numTiles.x + tileCoord.x + eyeIndex * numTiles.x * numTiles.y) * TILE_MAX_FRAGMENTS;
}

// Index for tileFragmentCountBuffer, linearize 2d tile coord
uint TileCountArrayIndex(const uint2 tileCoord, const uint eyeIndex)
{
    return tileCoord.y * numTiles.x + tileCoord.x + eyeIndex * numTiles.x * numTiles.y;
}

bool IsValidTileCoord(const uint2 tileCoord)
{
    return all(tileCoord >= uint2(0, 0)) && all(tileCoord < numTiles);
}

float LinearEyeDepth(float rawdepth)
{
    float NearClip = nearClip;
    float FarClip = farClip;

    float x, y, z, w;
#if SHADER_API_METAL || SHADER_API_D3D11_9X || SHADER_API_D3D11
    x = -1.0 + FarClip / NearClip;
    y = 1;
    z = x / FarClip;
    w = 1 / FarClip;
#else
    x = 1.0 - FarClip / NearClip;
    y = FarClip / NearClip;
    z = x / FarClip;
    w = y / FarClip;
#endif

    return 1.0 / (z * rawdepth + w);
}

float ComputePsfIndex(const uint2 screenPosition, const float depth, const uint eyeIndex)
{
    // depth buffer only provides distance along camera view direction, we have to take into account xy screen position ourselves
    float zDistance = LinearEyeDepth(depth);
    
    float2 interp = float2((float) screenPosition.x / (float) resolution.x, (float) screenPosition.y / (float) resolution.y);
    
    float3 ll = RIGHT_EYE ? rightFarLowerLeft : farLowerLeft;
    float3 lr = RIGHT_EYE ? rightFarLowerRight : farLowerRight;
    float3 ul = RIGHT_EYE ? rightFarUpperLeft : farUpperLeft;
    float3 ur = RIGHT_EYE ? rightFarUpperRight : farUpperRight;

    float3 a = lerp(ll, lr, interp.xxx);
    float3 b = lerp(ul, ur, interp.xxx);
    float3 c = lerp(a, b, interp.yyy);
    
    return (zDistance / farClip) * length(c);
}

float3 BlurRadii(float depth, uint channel, uint eyeIndex)
{
    float3 psfIds = ObjectIndices(depth);
    float blurRadius = LerpPsfRadiusStereo(psfIds, channel, eyeIndex);
    return float3(floor(blurRadius), ceil(blurRadius), blurRadius);
}

// max radii for each color channel
float3 MaxBlurRadii(float psfIndex, uint eyeIndex)
{
    float3 result = float3(0.0f, 0.0f, 0.0f);
    result = max(result, BlurRadii(psfIndex, 0, eyeIndex));
    result = max(result, BlurRadii(psfIndex, 1, eyeIndex));
    result = max(result, BlurRadii(psfIndex, 2, eyeIndex));
    
    return result;
}

float ComputeSortDepth(const uint2 screenPosition, const float depth)
{
    return depth;
}

// check if given fragmentCoord + blur overlaps with given tileCoord
bool OverlapsTile(const uint2 tileCoord, const int2 fragmentCoord, const float blurRadius)
{
    // The two corners of the neighboring tile.
    const int2 tileMin = tileCoord * TILE_SIZE;
    const int2 tileMax = tileMin + (TILE_SIZE - 1);

    // Distance of the center fragment to the edges of the neighboring tile
    const int2 distToMin = abs(tileMin - fragmentCoord);
    const int2 distToMax = abs(tileMax - fragmentCoord);
    
    // Evaluate the side and corner conditions
    return
        // Vertical neighbors
        (fragmentCoord.x >= tileMin.x && fragmentCoord.x <= tileMax.x && (distToMin.y <= blurRadius || distToMax.y <= blurRadius)) ||

        // Horizontal neighbors
        (fragmentCoord.y >= tileMin.y && fragmentCoord.y <= tileMax.y && (distToMin.x <= blurRadius || distToMax.x <= blurRadius)) ||

        // Oblique neighbors
        (distToMin.x <= blurRadius && distToMin.y <= blurRadius) ||
        (distToMin.x <= blurRadius && distToMax.y <= blurRadius) ||
        (distToMax.x <= blurRadius && distToMin.y <= blurRadius) ||
        (distToMax.x <= blurRadius && distToMax.y <= blurRadius);
}

// unused currently
// [numthreads(TILE_SIZE, TILE_SIZE, 1)]
// void FragmentBufferBuild(uint3 id : SV_DispatchThreadID)
// {
// 	const uint2 fragmentCoord = id.xy;
// 	if (any(fragmentCoord >= resolution))
// 		return;
// 	const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);

// 	const float3 color = iColor[fragmentCoord].xyz;
// 	const float depth = iDepth[fragmentCoord].x;

// 	FragmentData fragmentData;
// 	fragmentData.color = color;
// 	fragmentData.screenPosition = float2(fragmentCoord);
// 	fragmentData.psfIndex = ComputePsfIndex(fragmentCoord, depth);
// 	fragmentData.blurRadius = MaxBlurRadii(fragmentData.psfIndex).z;

// 	fragmentBuffer[fragmentIndex] = fragmentData;
// }

void TileBufferBuildHelper(const uint3 id, const float3 color, const float depth)
{
    const uint2 fragmentCoord = id.xy;
    const uint eyeIndex = id.z;
    const uint fragmentIndex = FragmentArrayIndex(fragmentCoord, eyeIndex);

    FragmentData fragmentData;
    fragmentData.color = color;
    fragmentData.screenPosition = float2(fragmentCoord);
    fragmentData.psfIndex = ComputePsfIndex(fragmentCoord, depth, eyeIndex);
    fragmentData.blurRadius = ceil(MaxBlurRadii(fragmentData.psfIndex, eyeIndex).z);
    
    // if (any(fragmentCoord != resolution / 2))
    // {
    //     fragmentData.color = float3(0.0f, 0.0f, 0.0f);
    //     fragmentData.blurRadius = 1.0f;
    // }

    fragmentBuffer[fragmentIndex] = fragmentData;

//--------------------

    const uint2 tileCoord = id.xy / TILE_SIZE;
    const uint2 threadId = id.xy % TILE_SIZE;
    //const uint2 fragmentCoord = id.xy;

    //const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);
    const uint tileIndex = TileArrayIndex(tileCoord, eyeIndex);
    const uint countIndex = TileCountArrayIndex(tileCoord, eyeIndex);

    //FragmentData fragmentData = fragmentBuffer[fragmentIndex];

    SortIndex sortIndex;
    sortIndex.fragmentIndex = fragmentIndex;
    sortIndex.depth = ComputeSortDepth(fragmentData.screenPosition, fragmentData.psfIndex);

    const uint2 size = min(resolution - tileCoord * TILE_SIZE, uint2(TILE_SIZE, TILE_SIZE));

    //tileSortBuffer[tileIndex + fragmentIndex] = sortIndex;
    tileSortBuffer[tileIndex + threadId.y * size.x + threadId.x] = sortIndex;

    if (all(threadId == 0))
    {
        tileFragmentCountBuffer[countIndex] = size.x * size.y;
    }
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void TileBufferBuild(uint3 id : SV_DispatchThreadID)
{
    if (any(id.xy >= resolution))
        return;

    const float3 color = iColorArray[id].xyz;
    const float depth = iDepthArray[id].x;

    TileBufferBuildHelper(id, color, depth);
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void TileBufferBuildEditor(uint3 id : SV_DispatchThreadID)
{
    if (any(id.xy >= resolution))
        return;

    const float3 color = iColor[id.xy].xyz;
    const float depth = iDepth[id.xy].x;

    TileBufferBuildHelper(id, color, depth);
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void TileBufferSplat(uint3 id : SV_DispatchThreadID)
{
    const uint2 tileCoord = id.xy / TILE_SIZE;
    const uint2 threadId = id.xy % TILE_SIZE;
    const uint2 fragmentCoord = id.xy;
    const uint eyeIndex = id.z;

    if (any(fragmentCoord >= resolution))
        return;

    const uint fragmentIndex = FragmentArrayIndex(fragmentCoord, eyeIndex);
    const uint countIndex = TileCountArrayIndex(tileCoord, eyeIndex);

    const FragmentData fragmentData = fragmentBuffer[fragmentIndex];
    
    SortIndex sortIndex;
    sortIndex.fragmentIndex = fragmentIndex;
    sortIndex.depth = ComputeSortDepth(fragmentData.screenPosition, fragmentData.psfIndex);
    
    const int numTilesSplat = CEIL_DIV(maxBlurRadiusCurrent, TILE_SIZE);

    for (int i = -numTilesSplat; i <= numTilesSplat; i++)
    {
        for (int j = -numTilesSplat; j <= numTilesSplat; j++)
        {
            const uint2 neighborOffset = uint2(i, j);
            const uint2 neighborTileCoord = tileCoord + neighborOffset;
            if (all(neighborOffset == uint2(0, 0)))
                continue;
            if (!IsValidTileCoord(neighborTileCoord))
                continue;
            if (!OverlapsTile(neighborTileCoord, fragmentData.screenPosition, fragmentData.blurRadius))
                continue;

            const uint neighborTileIndex = TileArrayIndex(neighborTileCoord, eyeIndex);
            const uint neighborCountIndex = TileCountArrayIndex(neighborTileCoord, eyeIndex);

            uint neighborFragmentCount;
            InterlockedAdd(tileFragmentCountBuffer[neighborCountIndex], 1, neighborFragmentCount);
            if (neighborFragmentCount < TILE_MAX_FRAGMENTS)
                tileSortBuffer[neighborTileIndex + neighborFragmentCount] = sortIndex;
        }
    }

    // tileFragmentCount by the end of this function is possibly too big
    // we will fix this in SortFragments
}

[numthreads(8, 8, 1)]
void BlurTest(uint3 id : SV_DispatchThreadID)
{
    // uint2 coords = id.xy;
    // float linearDepth = LinearEyeDepth(iDepth[coords].x);
    // oColor[id.xy] = float4(linearDepth, linearDepth, linearDepth, 1.0f);
    // return;
    
    uint texWidth = resolution.x;
    uint texHeight = resolution.y;
    uint texDepth = 2;
    //oColor.GetDimensions(texWidth, texHeight, texDepth);

    // oColor[id.xy] = float4()

    // float3 texCoords = float3((float) id.x / texWidth, (float)id.y)
    // psfTexture.SampleLevel(samplerpsfTexture, texCoords, 0)
        
    if (id.x >= texWidth || id.y >= texHeight || id.z >= texDepth)
        return;
    // float4 color = float4(0.0, 0.0, 0.0, 1.0);
    // uint cnt = 0;
    // for (int i = -BOX_BLUR_RADIUS; i <= BOX_BLUR_RADIUS; i++)
    // {
    //     for (int j = -BOX_BLUR_RADIUS; j <= BOX_BLUR_RADIUS; j++)
    //     {
    //         if (id.x + i >= 0 && id.x + i < texWidth && id.y + j >= 0 && id.y + j < texHeight) 
    //         {
    //             color += iColor.Load(int4(id, 0)) * BOX_BLUR_WEIGHT;
    //             //color += iColor[id.xy + int2(i, j), id.z] * BOX_BLUR_WEIGHT;
    //             cnt++;
    //         }
    //     }
    // }
    if (id.z == 0)
        oColorArray[id] = float4(1.0, 0.0, 0.0, 1.0);
    else
        oColorArray[id] = float4(0.0, 1.0, 0.0, 1.0);
    //oColor[id] = color;
}

groupshared uint fragmentIndices[TILE_MAX_FRAGMENTS];
groupshared float fragmentDepths[TILE_MAX_FRAGMENTS];

[numthreads(SORT_GROUP_SIZE,1,1)]
void SortFragments(uint3 id_dispatch : SV_DispatchThreadID) {
    const uint threadId = id_dispatch.x % SORT_GROUP_SIZE;
    const uint eyeIndex = id_dispatch.x / SORT_GROUP_SIZE;
    const uint2 tileCoord = id_dispatch.yz;
    
    const uint countIndex = TileCountArrayIndex(tileCoord, eyeIndex);
    const uint tileIndex = TileArrayIndex(tileCoord, eyeIndex);

    // fixup tile fragment count
    if (threadId == 0)
    {
        if (tileFragmentCountBuffer[countIndex] > TILE_MAX_FRAGMENTS)
            tileFragmentCountBuffer[countIndex] = TILE_MAX_FRAGMENTS;
    }
    
    GroupMemoryBarrierWithGroupSync();
    
    const uint fragmentCount = tileFragmentCountBuffer[countIndex];

    /* Read all TILE_MAX_FRAGMENTS while striding */
    for (uint batchId = 0; batchId < TILE_MAX_FRAGMENTS / SORT_GROUP_SIZE; batchId++)
    {
        uint offset = batchId * SORT_GROUP_SIZE + threadId;
        if (offset < fragmentCount)
        {
            SortIndex sortIndex = tileSortBuffer[tileIndex + offset];
            fragmentIndices[offset] = sortIndex.fragmentIndex;
            fragmentDepths[offset] = sortIndex.depth;
        }
        else
        {
            fragmentDepths[offset] = FLT_MAX;
        }
    }
    GroupMemoryBarrierWithGroupSync();

    for (uint k = 2; k <= TILE_MAX_FRAGMENTS; k *= 2) 
    {
        /* We are alternately sorting groups of size k (blue boxes) */
        for (uint j = k / 2; j > 0; j /= 2)
        {
            /* We are performing swaps with stride j */
            for (uint batchId = 0; batchId < SORT_ELEMENTS_PER_THREAD; batchId++)
            {
                /* We don't have enough threads so each thread is responsible for SORT_ELEMENTS_PER_THREAD swaps */
                const uint i = batchId * SORT_GROUP_SIZE + threadId;
                /* Insert a 0 at position defined by j */
                const uint id1 = i * 2 - ((j - 1) & i);
                /* Perform the crossover sort if this is the first in the block (orange box) */
                const uint id2 = id1 ^ (k == 2 * j ? k - 1 : j);

                if (fragmentDepths[id1] > fragmentDepths[id2])
                {
                    float ftmp = fragmentDepths[id1];
                    fragmentDepths[id1] = fragmentDepths[id2];
                    fragmentDepths[id2] = ftmp;

                    uint itmp = fragmentIndices[id1];
                    fragmentIndices[id1] = fragmentIndices[id2];
                    fragmentIndices[id2] = itmp;
                }
            }

            // roughly equivalent to __syncthreads(), explicitly fences over shared memory only
            GroupMemoryBarrierWithGroupSync();
        }
    }

    for (batchId = 0; batchId < TILE_MAX_FRAGMENTS / SORT_GROUP_SIZE; batchId++)
    {
        uint offset = batchId * SORT_GROUP_SIZE + threadId;
        SortIndex sortIndex;
        sortIndex.fragmentIndex = fragmentIndices[offset];
        sortIndex.depth = fragmentDepths[offset];
        tileSortBuffer[tileIndex + offset] = sortIndex;
    }
}

// PSF texture sampling code
// https://discussions.unity.com/t/compute-shader-samplerstate/490835 - Unity imposes strict naming convention, even in compute shaders
// furthermore, it seems it doesn't even respect the parameters set below, only those from within C#
SamplerState samplerpsfTexture
{
    Filter = MIN_MAG_MIP_LINEAR;
    AddressU = Border;
    AddressV = Border;
    AddressW = Border;
    BorderColor = float4(0.0f, 0.0f, 0.0f, 1.0f);
};

/*
// Transform depth to PSF index
vec3 sphericalCoordsToPsfIndex(const vec3 sphericalCoords)
{
    // Get the corresponding PSF index
    const vec3 psfIds = objectDistanceIndices(sphericalCoords.z);

    // Maximum PSF sizes
    const uint maxPsfRadius = sTiledSplatBlurData.uiMaxBlurRadiusCurrent;
    const uint maxPsfDiameter = maxPsfRadius * 2 + 1;

    // Return the texture layer
    return vec3(maxPsfRadius, maxPsfRadius, psfIndexToLayerId(psfIds));
}

// converts the input psf index to the corresponding layer ID
float psfIndexToLayerId(const vec3 d)
{
    // Get the first layer and the number of layers
    const uint idx = psfParamArrayIndex(uint(d[0]), 0);
    const float startLayer = float(sInterpolatedPsfParamBuffer[idx].uiStartLayer);
    const float numLayers = float(sInterpolatedPsfParamBuffer[idx].uiNumLayers);

    // Return the texture layer
    return startLayer + numLayers * fract(d[2]);
}
*/

// Note that vPsfIndex is containing depth at beginning, then only gets converted to dioptres at the end of tile_buffer_build
// Our tile buffer build is less complex, so we just keep it as depth all the way through until we need to sample
// Csoba reference: sphericalCoordsToPsfIndex (above)
float RealPsfIndex(float psfIndex, uint eyeIndex) {
    // psfIndex = depth
    float3 psfIds = ObjectIndices(psfIndex);
    // psfIds = index into object dioptres

    // layers info stored in R channel only
    uint idx = PsfParamArrayIndex((uint) psfIds[0], 0);

    
    float startLayer = (float) (RIGHT_EYE ? rightInterpolatedPsfParams[idx].startLayer : interpolatedPsfParams[idx].startLayer);
    float numLayers = (float) (RIGHT_EYE ? rightInterpolatedPsfParams[idx].numLayers : interpolatedPsfParams[idx].numLayers);

    return startLayer + numLayers * frac(psfIds[2]);
}

float3 SamplePsf(const uint2 fragmentCoord, const FragmentData fragmentData, uint eyeIndex)
{
    // PSFs are centered in 3D texture
    uint maxPsfRadius = RIGHT_EYE ? rightMaxBlurRadiusCurrent : maxBlurRadiusCurrent;
    float psfIndex = RealPsfIndex(fragmentData.psfIndex, eyeIndex);
    
    int2 delta = int2(fragmentCoord.x - fragmentData.screenPosition.x, fragmentCoord.y - fragmentData.screenPosition.y);
    uint lowerLayerExtent = RIGHT_EYE ? rightPsfTextureLayerExtents[floor(psfIndex)] : psfTextureLayerExtents[floor(psfIndex)];
    uint upperLayerExtent = RIGHT_EYE ? rightPsfTextureLayerExtents[ceil(psfIndex)] : psfTextureLayerExtents[ceil(psfIndex)];
    uint maxExtent = max(lowerLayerExtent, upperLayerExtent);
    
    if (any(abs(delta) > int2(maxExtent, maxExtent)))
    {
        return float3(0.0f, 0.0f, 0.0f);
    }
    
    float3 texCoordIndices = float3(fragmentCoord.x - fragmentData.screenPosition.x + maxPsfRadius, fragmentCoord.y - fragmentData.screenPosition.y + maxPsfRadius, psfIndex);

    uint width, height, depth;
    if (RIGHT_EYE) 
    {
        rightPsfTexture.GetDimensions(width, height, depth);
    }
    else 
    {
        psfTexture.GetDimensions(width, height, depth);
    }
    
    
    // offset by half-texel since we want to sample exactly at the center of pixel
    float3 texCoords = (texCoordIndices + float3(0.5f, 0.5f, 0.5f)) / float3(width, height, depth);
    
    // have to implement CLAMP_TO_BORDER ourselves since Unity does not support this texture wrap mode
    if (any(texCoords < 0.0f) || any(texCoords > 1.0f))
    {
        return float3(0.0f, 0.0f, 0.0f);
    }
    else
    {
        return RIGHT_EYE ? rightPsfTexture.SampleLevel(samplerpsfTexture, texCoords, 0).rgb : psfTexture.SampleLevel(samplerpsfTexture, texCoords, 0).rgb;
    }
}

groupshared FragmentData tileFragments[SHARED_ARRAY_SIZE];
groupshared uint fragmentCount;

float3 ConvolveHelper(uint3 id)
{
    const uint2 tileCoord = id.xy / TILE_SIZE;
    const uint2 threadId = id.xy % TILE_SIZE;
    const uint2 fragmentCoord = id.xy;
    const uint eyeIndex = id.z;

    const bool invalid = any(fragmentCoord >= resolution);

    const uint fragmentIndex = FragmentArrayIndex(fragmentCoord, eyeIndex);
    const uint countIndex = TileCountArrayIndex(tileCoord, eyeIndex);
    const uint tileIndex = TileArrayIndex(tileCoord, eyeIndex);

    //const uint fragmentCount = tileFragmentCountBuffer[countIndex];

    const uint threadIndex = threadId.y * TILE_SIZE + threadId.x;

    if (threadIndex == 0)
        fragmentCount = tileFragmentCountBuffer[countIndex];
    GroupMemoryBarrierWithGroupSync();
    
    // oColor[fragmentCoord] = float4(invalid ? 1.0f : 0.0f, 0.0f, 0.0f, 1.0f);
    // return;
    // oColor[fragmentCoord] = float4(fragmentCount, 0.0f, 0.0f, 1.0f);
    // return;
    // return float3(fragmentCount, 0.0f, 0.0f);
    
    /* Depth sorted alpha blending using premultiplied alpha */
    float3 result = float3(0, 0, 0);
    float3 alpha = float3(0, 0, 0);

    /* Groupshare ver. */
    for (uint batchId = 0; batchId < CEIL_DIV(fragmentCount, SHARED_ARRAY_SIZE); batchId++)
    {
        uint offset = batchId * SHARED_ARRAY_SIZE + threadIndex;
        SortIndex sortIndex = tileSortBuffer[tileIndex + offset];
        if (offset < fragmentCount)
            tileFragments[threadIndex] = fragmentBuffer[sortIndex.fragmentIndex];
        GroupMemoryBarrierWithGroupSync();

        if (!invalid)
        {
            uint cnt = min(fragmentCount - batchId * SHARED_ARRAY_SIZE, SHARED_ARRAY_SIZE);
            for (uint i = 0; i < cnt; i++)
            {
                
                FragmentData fragmentData = tileFragments[i];
                // if (all(uint2(fragmentData.screenPosition.x, fragmentData.screenPosition.y) == fragmentCoord))
                // {
                //     oColor[fragmentCoord] = float4(fragmentData.psfIndex, fragmentData.psfIndex, fragmentData.psfIndex, 1.0f);
                //     break;
                // }
                float3 weight = SamplePsf(fragmentCoord, fragmentData, eyeIndex);

                /* Regular weighted summation */
                //result += weight * fragmentData.color;

                /* Back to front alpha blending */
                result = weight * fragmentData.color + (1.0 - weight) * result;
                alpha = weight + (1.0 - weight) * alpha;

                /* Front to back alpha blending */
                // result += (1.0 - alpha) * weight * fragmentData.color;
                // alpha = weight + (1.0 - weight) * alpha;
            }
        }
        GroupMemoryBarrierWithGroupSync();
    }

    /* No groupshare ver. */
    // for (uint i = 0; i < fragmentCount; i++)
    // {
    // 	SortIndex sortIndex = tileSortBuffer[tileIndex + i];
    // 	FragmentData fragmentData = fragmentBuffer[sortIndex.fragmentIndex];
    // 	float3 weight = SamplePsf(fragmentCoord, fragmentData);

    // 	result += weight * fragmentData.color;

    // 	// result += (1.0 - alpha) * weight * fragmentData.color;
    // 	// alpha = weight + (1.0 - weight) * alpha;

    if (all(alpha != 0.0f))
        return result / alpha;
    return float3(0.0f, 0.0f, 0.0f);
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void Convolve(uint3 id : SV_DispatchThreadID)
{
    float3 result = ConvolveHelper(id);

    // clear screen before writing over
    if (all(id.xy < resolution))
        oColorArray[id] = float4(result.xyz, 1.0f);
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void ConvolveEditor(uint3 id : SV_DispatchThreadID)
{
    float3 result = ConvolveHelper(id);

    // clear screen before writing over
    if (all(id.xy < resolution))
        oColor[id.xy] = float4(result.xyz, 1.0f);
}

