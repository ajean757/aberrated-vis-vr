// Each #kernel tells which function to compile; you can have many kernels
//#pragma kernel FragmentBufferBuild
#pragma kernel TileBufferBuild
#pragma kernel TileBufferSplat
#pragma kernel SortFragments
#pragma kernel BlurTest
#pragma kernel InterpolatePSFTexture

//#pragma enable_cbuffer

#define TILE_SIZE 16
#define TILE_MAX_FRAGMENTS 8192

//CBUFFER_START(TileSplatParams)
cbuffer TileSplatParams
{
    uint2 numTiles;
    uint2 resolution;

    uint minBlurRadiusCurrent;
    uint maxBlurRadiusCurrent;
	
    uint numObjectDioptres;
    float objectDioptresMin;
    float objectDioptresMax;
    float objectDioptresStep;
    uint numApertures;
    float aperturesMin;
    float aperturesMax;
    float aperturesStep;
    uint numFocusDioptres;
    float focusDioptresMin;
    float focusDioptresMax;
    float focusDioptresStep;
};
//CBUFFER_END

cbuffer CameraData
{
    float aperture;
    float focusDistance;
};

struct FragmentData
{
    float3 color;
    float2 screenPosition;
    float psfIndex; // depth of some kind
    float blurRadius;
};

RWStructuredBuffer<FragmentData> fragmentBuffer;

RWStructuredBuffer<uint> tileFragmentCountBuffer;

struct SortIndex
{
    uint fragmentIndex;
    float depth; // uses "sort" depth which adds a term based on index to avoid Z-fighting
};

RWStructuredBuffer<SortIndex> tileSortBuffer;

Texture2D<float4> iColor;
RWTexture2D<float4> oColor;

// depth is stored in .x
Texture2D<float4> iDepth;

uint FragmentArrayIndex(const uint2 fragmentCoord)
{
    return fragmentCoord.y * resolution.x + fragmentCoord.x;
}

// Index for tileSortBuffer
uint TileArrayIndex(const uint2 tileCoord)
{
    return (tileCoord.y * numTiles.x + tileCoord.x) * TILE_MAX_FRAGMENTS;
}

// Index for tileFragmentCountBuffer
uint TileCountArrayIndex(const uint2 tileCoord)
{
    return tileCoord.y * numTiles.x + tileCoord.x;
}

bool IsValidTileCoord(const uint2 tileCoord)
{
    return all(tileCoord >= uint2(0, 0)) && all(tileCoord < numTiles);
}

float3 SphericalCoordinates(const uint2 screenPosition, const float depth)
{
	// do something
}

float ComputePsfIndex(const uint2 screenPosition, const float depth)
{
    return depth;
}

// max radii for each color channel
float3 MaxBlurRadii(float psfIndex)
{
    return 1;
}

float ComputeSortDepth(const uint2 screenPosition, const float depth)
{
    return depth;
}

// check if given fragmentCoord + blur overlaps with given tileCoord
bool OverlapsTile(const uint2 tileCoord, const uint2 fragmentCoord, const float blurRadius)
{
    return true;
}

// unused currently
// [numthreads(TILE_SIZE, TILE_SIZE, 1)]
// void FragmentBufferBuild(uint3 id : SV_DispatchThreadID)
// {
// 	const uint2 fragmentCoord = id.xy;
// 	if (any(fragmentCoord >= resolution))
// 		return;
// 	const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);

// 	const float3 color = iColor[fragmentCoord].xyz;
// 	const float depth = iDepth[fragmentCoord].x;

// 	FragmentData fragmentData;
// 	fragmentData.color = color;
// 	fragmentData.screenPosition = float2(fragmentCoord);
// 	fragmentData.psfIndex = ComputePsfIndex(fragmentCoord, depth);
// 	fragmentData.blurRadius = MaxBlurRadii(fragmentData.psfIndex).z;

// 	fragmentBuffer[fragmentIndex] = fragmentData;
// }

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void TileBufferBuild(uint3 id : SV_DispatchThreadID)
{
    const uint2 fragmentCoord = id.xy;
    if (any(fragmentCoord >= resolution))
        return;
    const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);

    const float3 color = iColor[fragmentCoord].xyz;
    const float depth = iDepth[fragmentCoord].x;

    FragmentData fragmentData;
    fragmentData.color = color;
    fragmentData.screenPosition = float2(fragmentCoord);
    fragmentData.psfIndex = ComputePsfIndex(fragmentCoord, depth);
    fragmentData.blurRadius = MaxBlurRadii(fragmentData.psfIndex).z;

    fragmentBuffer[fragmentIndex] = fragmentData;

//--------------------

    const uint2 tileCoord = id.xy / TILE_SIZE;
    const uint2 threadId = id.xy % TILE_SIZE;
	//const uint2 fragmentCoord = id.xy;

	//const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);
    const uint tileIndex = TileArrayIndex(tileCoord);
    const uint countIndex = TileCountArrayIndex(tileCoord);

	//FragmentData fragmentData = fragmentBuffer[fragmentIndex];

    SortIndex sortIndex;
    sortIndex.fragmentIndex = fragmentIndex;
    sortIndex.depth = ComputeSortDepth(fragmentData.screenPosition, fragmentData.psfIndex);

    tileSortBuffer[tileIndex + fragmentIndex] = sortIndex;

    if (all(threadId == 0))
    {
        tileFragmentCountBuffer[countIndex] = TILE_SIZE * TILE_SIZE;
    }
}

[numthreads(TILE_SIZE, TILE_SIZE, 1)]
void TileBufferSplat(uint3 id : SV_DispatchThreadID)
{
    const uint2 tileCoord = id.xy / TILE_SIZE;
    const uint2 threadId = id.xy % TILE_SIZE;
    const uint2 fragmentCoord = id.xy;

    const uint fragmentIndex = FragmentArrayIndex(fragmentCoord);
    const uint countIndex = TileCountArrayIndex(tileCoord);

    const FragmentData fragmentData = fragmentBuffer[fragmentIndex];
	
    SortIndex sortIndex;
    sortIndex.fragmentIndex = fragmentIndex;
    sortIndex.depth = ComputeSortDepth(fragmentData.screenPosition, fragmentData.psfIndex);

    const int numTilesSplat = 1;

    for (int i = -numTilesSplat; i <= numTilesSplat; i++)
    {
        for (int j = -numTilesSplat; j <= numTilesSplat; j++)
        {
            const uint2 neighborOffset = uint2(i, j);
            const uint2 neighborTileCoord = tileCoord + neighborOffset;
            if (all(neighborOffset == uint2(0, 0)))
                continue;
            if (!IsValidTileCoord(neighborTileCoord))
                continue;
            if (!OverlapsTile(neighborTileCoord, fragmentData.screenPosition, fragmentData.blurRadius))
                continue;

            const uint neighborTileIndex = TileArrayIndex(neighborTileCoord);
            const uint neighborCountIndex = TileCountArrayIndex(neighborTileCoord);

            uint neighborFragmentCount;
            InterlockedAdd(tileFragmentCountBuffer[neighborCountIndex], 1, neighborFragmentCount);
            tileSortBuffer[neighborTileIndex + neighborFragmentCount] = sortIndex;
        }
    }
}

[numthreads(8, 8, 1)]
void BlurTest(uint3 id : SV_DispatchThreadID)
{
    uint texWidth;
    uint texHeight;
    iColor.GetDimensions(texWidth, texHeight);
    if (id.x >= texWidth || id.y >= texHeight)
        return;
    float4 color = float4(0.0, 0.0, 0.0, 1.0);
    uint cnt = 0;
    for (int i = -10; i <= 10; i++)
    {
        for (int j = -10; j <= 10; j++)
        {
            if (id.x + i >= 0 && id.x + i < texWidth && id.y + j >= 0 && id.y + j < texHeight)
            {
                color += iColor[id.xy + int2(i, j)];
                cnt++;
            }
        }
    }
    color /= cnt;
	//color.x = _iDepth[id.xy].x;
    oColor[id.xy] = color;
}


#define MAX_FRAGMENTS_PER_TILE 1024

RWStructuredBuffer<uint> indices;
RWStructuredBuffer<float> depths;

groupshared uint fragmentIndices[MAX_FRAGMENTS_PER_TILE];
groupshared float fragmentDepths[MAX_FRAGMENTS_PER_TILE];

[numthreads(MAX_FRAGMENTS_PER_TILE, 1, 1)]
void SortFragments(uint3 id_in_tile : SV_DispatchThreadID)
{
    uint id = id_in_tile.x;
    fragmentIndices[id] = indices[id];
    fragmentDepths[id] = depths[id];
    GroupMemoryBarrierWithGroupSync();

    for (uint k = 2; k <= MAX_FRAGMENTS_PER_TILE; k *= 2)
    {
        for (uint j = k / 2; j > 0; j /= 2)
        {
            uint i = id;
            uint l = i ^ j;
            if (l > i)
            {
                if (((i & k) == 0 && fragmentDepths[i] > fragmentDepths[l]) || ((i & k) != 0 && fragmentDepths[i] < fragmentDepths[l]))
                {
                    float ftmp = fragmentDepths[i];
                    fragmentDepths[i] = fragmentDepths[l];
                    fragmentDepths[l] = ftmp;

                    uint itmp = fragmentIndices[i];
                    fragmentIndices[i] = fragmentIndices[l];
                    fragmentIndices[l] = itmp;
                }
            }

			// roughly equivalent to __syncthreads(), explicitly fences over shared memory only
            GroupMemoryBarrierWithGroupSync();
        }
    }

    indices[id] = fragmentIndices[id];
    depths[id] = fragmentDepths[id];
}

struct PsfParam
{
    uint minBlurRadius; // px
    uint maxBlurRadius; // px
    uint weightStartIndex;
    float blurRadiusDeg;
};

StructuredBuffer<float> psfWeights;
StructuredBuffer<PsfParam> psfParams;


struct CoordinatesIndices
{
    uint2 fragmentCoord;
    uint2 tileId;
    uint2 threadId;
    uint threadIndex;
    uint arrayIndex;
    uint countArrayIndex;
    uint numTileFragments;
    uint groupSize;
    uint batchSize;
};

// Interpolate PsfParam to squeeze away the aperture diameter and focus distance dimensions (these are fixed in a given frame)
// Unlike Csoba, we perform the calculation of 3D texture on CPU instead
struct InterpolatedPsfParam
{
    uint startLayer;
    uint numLayers;
    float blurRadius;
};

StructuredBuffer<InterpolatedPsfParam> interpolatedPsfParams;
StructuredBuffer<uint> psfInterpolationBuffer; // note: 1-indexed, 0th entry contains total count

// 2 "views" into the same underlying texture - must use psfImage to write, then psfTexture to read
// HLSL runtime enforces that the same underlying texture resource cannot be used both in read and write mode
// Need the "read" view even though RWTexture would suggest it is also readable, because RWTexture3D doesn't support
// texture sampling, which we need

// also Csoba's code uses r11_g11_b10 (11 bits for R, G and 10 bits for B) to compress the texture memory used by default
// float4 is probably simpler? we could also consider this optimization in the future.
RWTexture3D<float4> psfImage;
Texture3D<float4> psfTexture;

float3 ApertureIndices(float aperture)
{
    float frac = (aperture - aperturesMin) / aperturesStep;
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 clampedIndices = clamp(unclampedIndices, 0, numApertures - 1);
    return float3(clampedIndices.x, clampedIndices.y, frac);
}

float3 FocusIndices(float focusDistance)
{
    float focusDioptres = 1.0f / focusDistance;
    float frac = (focusDioptres - focusDioptresMin) / focusDioptresStep;
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 clampedIndices = clamp(unclampedIndices, 0, numFocusDioptres - 1);
    return float3(clampedIndices.x, clampedIndices.y, frac);
}

// d = object distance index, c = channel index. We assume rank of channel dimension is always 3 (RGB)
uint PsfParamArrayIndex(uint d, uint c)
{
    return d * 3 + c;
}

// l = layer ID, d = "base" PSF that l is associated with
float LayerIdToPsfIndex(uint d, uint l)
{
    uint idx = PsfParamArrayIndex(d, 0); // start layer + num layers is only stored in R entry
    uint s = interpolatedPsfParams[idx].startLayer;
    uint n = interpolatedPsfParams[idx].numLayers;
    return d + float(l - s) / float(n);
}

float3 LayerIdToPsfIndices(uint d, uint l)
{
    float frac = LayerIdToPsfIndex(d, l);
    int2 unclampedIndices = int2(floor(frac), ceil(frac));
    int2 clampedIndices = clamp(unclampedIndices, 0, numObjectDioptres - 1);
    return float3(clampedIndices.x, clampedIndices.y, frac);
}

float LerpPsfRadius(float3 d, uint c)
{
    float psfRadius0 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[0], c)].blurRadius;
    float psfRadius1 = interpolatedPsfParams[PsfParamArrayIndex((uint) d[0], c)].blurRadius;
    return lerp(psfRadius0, psfRadius1, d[2]);
}

bool IsSamplePadding(int2 sampleCoords, float3 psfIds)
{
	// calculate largest blur radius across all channels
    float maxBlurRadius = 0.0f;
    for (int i = 0; i < 3; i += 1)
    {
        float blurRadius = LerpPsfRadius(psfIds, i);
        maxBlurRadius = max(maxBlurRadius, blurRadius);
    }
	
    int2 lowerLeft = int2(int(maxBlurRadiusCurrent) - maxBlurRadius);
    int2 upperRight = int2(int(maxBlurRadiusCurrent) + maxBlurRadius);
    bool isPadding = any(sampleCoords < lowerLeft) || any(sampleCoords > upperRight);
    return isPadding;
}

// bilinear interpolation
float lerp2(
	float f00,
	float f01,
	float f10,
	float f11,
	float x01,
	float x10
)
{
    float a = lerp(f00, f01, x01);
    float b = lerp(f10, f11, x01);
    return lerp(a, b, x10);
}

// trilinear interpolation
float lerp3(
	float f000,
	float f001,
	float f010,
	float f011,
	float f100,
	float f101,
	float f110,
	float f111,
	float x001,
	float x010,
	float x100
)
{
    float a = lerp2(f000, f001, f010, f011, x001, x010);
    float b = lerp2(f100, f101, f110, f111, x001, x010);
    return lerp(a, b, x100);
}

uint PsfParamBufferIndex(uint d, uint a, uint f, uint c)
{
    return d * (3 * numApertures * numFocusDioptres)
		+ c * (numApertures * numFocusDioptres)
		+ a * (numFocusDioptres)
		+ f;
}

// closed form sum of (2r+1)^2 for r from a to b (inclusive) 
// apparently calculated using Mathematica
uint WeightOffset(int a, int b)
{
    return (a - 4 * a * a * a + (1 + b) * (1 + 2 * b) * (3 + 2 * b)) / 3;
}

uint PsfWeightBufferIndex(uint psfParamIdx, uint r, uint minR, uint2 sc)
{
    uint base = psfParams[psfParamIdx].weightStartIndex;
    uint sampleOffset = sc.y * (2 * r + 1) + sc.x;
    if (r == minR)
    {
        return base + sampleOffset;
    }
    else
    {
        return base + WeightOffset(minR, r - 1) + sampleOffset;
    }

}

float PsfWeight(uint psfParamIdx, uint r, uint2 sc)
{
    uint minR = psfParams[psfParamIdx].minBlurRadius;
    uint maxR = psfParams[psfParamIdx].maxBlurRadius;
    return (r >= minR && r <= maxR) ? psfWeights[PsfWeightBufferIndex(psfParamIdx, r, minR, sc)] : 0.0f;
}

float SamplePsfWeightBufferPadded(float3 d, float3 a, float3 f, uint c, uint r, uint2 scp)
{
	// remove padding from sample coordinates
    int2 sc = int2(scp) - maxBlurRadiusCurrent + r;
    
	// determine if we are outside the spatial extent of the PSF entry we are sampling
    int2 lowerLeft = int2(0);
    int2 upperRight = int2(2 * r + 1);
    if (any(sc < lowerLeft) || any(sc >= upperRight))
    {
        return 0.0f;
    }
	
	// trilinearly interpolate over object distance, aperture diameter, focus distance
    return lerp3(
		PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[0], (uint) f[0], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[0], (uint) f[1], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[1], (uint) f[0], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[0], (uint) a[1], (uint) f[1], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[0], (uint) f[0], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[0], (uint) f[1], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[1], (uint) f[0], c), r, sc),
		PsfWeight(PsfParamBufferIndex((uint) d[1], (uint) a[1], (uint) f[1], c), r, sc),
		f[2],
		a[2],
		d[2]
	);
}

float SamplePsfWeightBufferPadded(float3 d, float3 a, float3 f, uint c, float3 r, uint2 scp)
{
    return lerp(
		SamplePsfWeightBufferPadded(d, a, f, c, (uint) r[0], scp),
		SamplePsfWeightBufferPadded(d, a, f, c, (uint) r[1], scp),
		r[2]
	);
}

// default from Csoba's code
#define INTERPOLATION_GROUP_SIZE 8
[numthreads(INTERPOLATION_GROUP_SIZE, INTERPOLATION_GROUP_SIZE, 1)]
void InterpolatePSFTexture(uint3 id_in_tile : SV_DispatchThreadID)
{
    uint2 sampleCoords = id_in_tile.xy;
    uint layerId = id_in_tile.z;

    float3 apertureIds = ApertureIndices(aperture);
    float3 focusIds = FocusIndices(focusDistance);
    uint psfId = psfInterpolationBuffer[layerId + 1];
    float3 psfIds = LayerIdToPsfIndices(psfId, layerId);
	
    uint numTextureLayers = psfInterpolationBuffer[0];
    if (layerId >= numTextureLayers)
        return;
    if (IsSamplePadding(sampleCoords, psfIds))
        return;
	
    float4 textureValue = float4(0.0f, 0.0f, 0.0f, 1.0f);
    for (uint c = 0; c < 3; c += 1)
    {
        float rFrac = LerpPsfRadius(ddx, c);
        float3 r = float3(floor(rFrac), ceil(rFrac), frac(rFrac));
        textureValue[c] = SamplePsfWeightBufferPadded(psfIds, apertureIds, focusIds, c, r, sampleCoords);
    }
	
    psfImage[id_in_tile] = textureValue;
}


// Interpolate PSFs to squeeze away the aperture diameter / focus distance dimensions, and also rearrange data into a 3D texture so that
// we can utilize hardware texture samplers to get good performance



// // Perform convolution
// uint unpackBatchFragments(const int batchId) {

// }

// float3 samplePsf(uint2 fragmentCoord, FragmentData) {

// }


// void convolve() {

// }

// void convolveFragment() {

// }

// [numthreads(32, 32, 1)] // fix this
// void Convolution(uint3 dispatchThreadID : SV_DispatchThreadID, uint3 localThreadID : SV_GroupThreadID)
// {
// 	// define coordinates by calling DEFINE_COORDINATES_INDICES
// 	CoordinatesIndices coords = GetCoordinatesIndices(SV_DispatchThreadID, SV_GroupThreadID);

// 	// extract number of fragments to process via sTileParametersBuffer
// 	uint uiNumFragments = sTileParametersBuffer[coords.countArrayIndex].uiNumFragmentsTotal; //todo 

// 	// Number of batches to make
// 	uint numBatches = (uiNumFragments + coords.batchSize - 1) / coords.batchSize;

// 	// Init the PSF data
// 			// csoba is currently empty

// 	// for each batch
// 			// unpack batch fragments to shared mem
// 			// perform convolution
// 	for (int batchId = 0; batchId < numBatches; ++batchId) {

// 	}

// 	// ignore out of bound pixels

// 	// normalize

// 	// write out convolution result

// }